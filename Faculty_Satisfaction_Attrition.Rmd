---
title: "Faculty Satisfaction and Turnover Analysis"
author: Chad Evans
output: 
  github_document:
  toc: true
always_allow_html: yes
params:
 d: !r Sys.Date() 

---
Built with `r getRversion()`.  Last run on `r params$d`.

* [Configure](#configure)
    + Libraries
    + directories
    + data
* [Munge](#munge)
* Exploratory Analysis
* [Descriptive Statistics](#descriptive-statistics)
* [Exploratory Factor Analysis](#exploratory-factor-analysis)
    + [Factors](#factors)
    + [Cronbach Alphas](#cronbach-alphas)
* [Confirmatory Factor Analysis](#confirmatory-factor-analysis)
    + [Measurement Invariance](#measurement-invariance)
* [Model Specification with Training Data](#model-specification-with-training-data)
    + [Linear Training Model with Robust SEs](#linear-training-model-with-robust-ses)
* [Model Evaluation with Training Data](#model-evaluation-with-test-data)
    + [Bayesian Multi-level Models](#bayesian-multi-level-models)
    
## Configure{#config}
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message=FALSE, fig.width=7, fig.height=7, fig.path='graphs/', cache.path ='cache/')
```

```{r Directories, include=FALSE}
Private_Cache <- "/Users/chadgevans/Research/Projects/Data/HERI/Cache"
Raw<-"/Users/chadgevans/Research/Projects/Data/HERI/Raw"
Munge<-"./munge"
Source<-"./src"
Graph<-"./graph"
Diagnostics<-"./diagnostics"
Doc<-"./doc"
```

```{r Libraries, include=FALSE,      eval=TRUE, echo=TRUE, warning=TRUE,error=FALSE, message=TRUE, tidy=TRUE, results='markup', cache=FALSE}
library(nFactors)
library(lavaan)
library(RColorBrewer)
library(psych)
library(semPlot)
library(semTools)
library(MASS)
library(knitr)
library(tidyverse)
library(corrplot)
library(sandwich)
library(lmtest)
library(gdata)
source("/Users/chadgevans/Research/Projects/Faculty_Classification/lib/nfCrossTable.R")
#source(file.path(Munge, "CenterIt.R"))
```

## Munge{#munge}
```{r Data Munge, message=FALSE}
source(file.path(Munge, "01_Merge_the_data.R"))
source(file.path(Munge, "02_Clean_the_data.R"))
source(file.path(Munge, "03_Recode.R"))
save(df, file=file.path(Private_Cache,"Cleaned_HERI.RData"))
```

```{r Clean Data Import, results='hide'}
load(file.path(Private_Cache,"Cleaned_HERI.RData"))
```

## Exploratory Analysis{#exploratory}
```{r, eval=FALSE}
source(file.path(Diagnostics, "Diagnostics.R"))
```

## Descriptive Statistics
```{r Descriptive_Stats}
GAPPAnames<-c("Full-time","Aspiring Academic","Career-Ender","Expert","Freelancer")
VARS<-c("AGE", "SEX","MARITAL2","RACEGROUP2","DEGEARN2","PRINACT2","INSTCONT","CARNEGIE2","BIGLAN","SELECTIVITY2","OBEREG")
table<-round(nfCrossTable(data=df[,VARS],CTvar=as.integer(df$GAPPANTT)),2)
colnames(table)<-GAPPAnames
rownames(table)<-c("Avg. Age","Female","Married","White","Ph.D.","Professional","Masters","BA or Less","Teacher","Researcher","Administrator/Other","Public","Research I","Research II","Research III/Doctoral","Bachelor's/Master's","Associates/Other","Hard/Applied","Hard/Pure","Soft/Applied","Soft/Pure","Other","Selective","East","West/Other","Midwest","South")
kable(table, caption = "Distribution of Adjunct Clusters by Work Characteristics")
prop.table(table(df$GAPPANTT))
```

## Exploratory Factor Analysis
This project will use data to help specify the model.  In order to prevent overfitting, I split the data into a training subset and a test subset (60/40).  The training data will be used for model development.  The test data will not have any role in construction of the model, making observations fully independent.  This helps to ensure that the final model I specify will generalize to the population.

```{r Split_data}
smp_size <- floor(0.60 * nrow(df)) ## 60% of the sample size (for training data)

set.seed(1)
train_ind <- sample(seq_len(nrow(df)), size = smp_size)

df_train <- df[train_ind, ]
df_test <- df[-train_ind, ]
```

Let's subset the satisfaction items (from the training data). Let's also exclude the global measure of job satisfaction (overall how satisfied are you with your job) as we are interested in components of job satisfaction--not overall job satisfaction.

```{r dfS_Munge}
dfS <- df_train %>% select(starts_with("SATIS"),-SATIS19,-SATIS_WORKPLACE,-SATIS_COMPENSATION)
```

We need to determine the optimal number of satisfaction factors for this analysis.  To do so, we calculate the correlation matrix and use eigenvalues, a scree plot and some theory to determine the optimal number of factors.  FIML is used for missingness.

```{r Scree_Plot, fig.cap="Scree Plot"}
corMat<-corFiml(dfS, covar = FALSE,show=FALSE) # Covariance Matrix from FIML
ev <- eigen(corMat) # get eigenvalues
ap <- parallel(subject=nrow(dfS),var=ncol(dfS),rep=100,cent=.05)
nS <- nScree(x=ev$values, aparallel=ap$eigen$qevpea)
plotnScree(nS)
```

This plot and these diagnostics suggest that three to four factors would be most appropriate (I opt for four).  Now we can conduct the exploratory Factor Analysis.  I chose the oblique option because I expect correlation between subjects latent satisfaction factors.  I chose principal axis (pa) factoring because I am most interested in identifying the underlying constructs in the data.

```{r Factor_loadings, fig.cap="Factor Loadings", fig.height=3.25, fig.width=3.25}
nfactors<-4
solution <- fa(r = corMat, covar=F, nfactors = nfactors, rotate = 'oblimin', fm = 'pa') 
print(solution$loadings, cutoff=.32)
```
 
The only item that failed to load (substantially) onto a factor was SATIS07 (satisfaction with office space).  Each of the four factors explains about 9-10\% of the variation.  How did the items load onto the factors and what factor names seem appropriate?

### Factors
```{r Factor_loadings_w_questions, fig.cap="Factor Loadings"}
Satis_questions<-read_csv(file.path(Raw,"Satisfaction_questions.csv"))[c(1:18, 20),]
ldf<-as_data_frame(solution$loadings[,]) %>%
  cbind(Satis_questions)
rm(Satis_questions)
Factor=NA
for(i in 1:nrow(ldf)){
  Factor[i]<-which.max(ldf[i,c(1:nfactors)])
}
ldf<- ldf %>% 
  mutate("Factor" = Factor) %>% 
  arrange(Factor) %>% 
  mutate(Factor = factor(Factor, labels = c("Work","Terms","Relationships","Benefits"))) 
ldf[,c(5,7)] 
```

Examining which items loaded onto which factors, we see that reasonable factor names would be work, terms, benefits and relationships.

```{r Factor_table, fig.cap="Factor Table"}
FT <- ldf %>% 
  select(Factor,`Respondent's satisfaction with:`) %>% 
  group_by(Factor) %>%
  mutate(id=1:n()) %>% 
  spread(Factor, `Respondent's satisfaction with:`) %>% 
  select(-id)
kable(FT)
```

### Cronbach Alphas

What is the internal validity of each factor?  Let's conduct a cronbach alpha measure of internal consistency.

```{r message=FALSE}
alphas=NULL
for(i in levels(ldf$Factor)){
    items<- ldf %>% 
      as_data_frame %>% 
      select(Item, Factor) %>%  
      filter(Factor==i) %>% 
      select(Item) %>% 
      unlist()
    rawalpha<- dfS[names(dfS) %in% items] %>% 
      psych::alpha()
    alphas[i]<-round(rawalpha$total$raw_alpha,2)
}
print(alphas)
```

Now we have an EFA-induced factor structure to utilize in a Confirmatory Factor Analysis.

## Confirmatory Factor Analysis
Now let's use this model to conduct the confirmatory factor analysis.  I utilize FIML to deal with missingness in the data.

```{r CFA Model, warning=FALSE}
CFAModel <- ' 
Work =~ SATIS05+SATIS06+SATIS07+SATIS08+SATIS13+SATIS14+SATIS15+SATIS18
Terms =~ SATIS01+SATIS04+SATIS12+SATIS16+SATIS17
Relations =~ SATIS09+SATIS10+SATIS11
Benefits =~ SATIS02+SATIS03+SATIS20
'
CFAfit<-cfa(CFAModel, data=dfS,  missing = "fiml")
summary(CFAfit, standardized=T, fit.measures = TRUE)
fitMeasures(CFAfit, c("chisq","cfi","tli","rmsea"))
```

The CFA model fits the data ok.  The cfi was almost .9, which is borderline acceptable.  Allison prefers to see a CFI and TLI above .95, ideally.  The RMSEA was 0.06, which is sub-optimal, but not terrible.  Allison prefers to see a RMSEA below .05.  We conclude that the measurement model fits the data ok.

### Measurement Invariance
I will now check measurement invariance on the measurement model (the CFA).

```{r Measurement Invariance, cache=TRUE, warning=FALSE, message=FALSE}
dfmi <- dfS %>% mutate("GAPPANTT"=df_train$GAPPANTT)

config <- sem(CFAModel, data = dfmi, missing = "fiml", group = "GAPPANTT")
weak <- sem(CFAModel, data = dfmi, group = "GAPPANTT",group.equal = "loadings", missing = "fiml") # Now the Latent Variables load the same onto each class of adjunct (with same CIs).  But Covariances, Intercepts, and variances are allowed to be different
strong <- sem(CFAModel, data = dfmi, group = "GAPPANTT",group.equal = c("loadings", "intercepts"), missing = "fiml") # Now the latent variables load the same onto each class of adjunct and ALSO the Intercept is the same.  Covariances and variances allowed to be different.
```

```{r Anova Table, cache=TRUE}
anovatable<-anova(config, weak, strong)
row.names(anovatable)<- c("Configural Model","Loadings Model","Intercepts Model")
fmc<-fitmeasures(config, c("cfi","rmsea"))
fml<-fitmeasures(weak, c("cfi","rmsea"))
fmi<-fitmeasures(strong, c("cfi","rmsea"))
fm<-rbind(fmc,fml,fmi)
anovatable[,c(2,3)]<-fm
colnames(anovatable)[2:3]<-c("CFI","RMSEA")
anovatable<-round(anovatable,3)
kable(anovatable)
```

# Model Specification with Training Data
For this project, I will use a backward stepping variable selection process. I begin with what are the (approx.) twenty most important variables (excluding satisfaction indicators for now). These variables are as follows:

```{r Potentially_Important_variables}
indvars<-c("GAPPANTT","PRINACT2","DEGEARN2","GENACT01","TIMEEMPLOYED","PRODUCTIVITY","SALARYALL")
instvars<-c("CARNEGIE2","INSTCONT","SELECTIVITY","BIGLAN","OBEREG") # Not including INSTTYPE bc of small cells
demvars<-c("NATENGSP","GENACT02","AGE","SEX","MARITAL2","NCHILD3","RACE")
Vars<-c("TURNINTENT",indvars,instvars,demvars)
Description<-c("Turnover Intentions","Adjunct Classifier","Principle Activity","Highest Degree Earned","Union Member","Time Employed","Scholarly Productivity","Salary","Carnegie Research Status","Control","Selectivity","Biglan Subject Area","Region","Native English-speaker","Citizenship status","Age","Sex","Marital Status","Number of Children","Race")
print(data.frame(cbind(Vars,Description)))

df_train <- df_train %>%
  select(one_of(Vars, names(dfS)))
```

Importantly, the variable selection process (and developmnt of the functional form) will occur on training data--not test data.  This will prevent overfitting.

## Linear Training Model with Robust SEs
Let's train a linear logistic regression model on these variables and use robust standard errors to deal with the fact that faculty members are clustered within institutions.  I also include a second order polynomial for the main numeric variables, but no interactions.  Robust SE is not the best solution to correlated errors, but seems adequate for model development.  The glm package used to estimate parameters uses iteratively reweighted least squares (IRLS).

```{r Robust_Logistic_regression}
# helper script to chain model variables into model formula
#paste("as.numeric(TURNINTENT)-1 ~", paste(c(indvars,instvars,demvars), collapse= "+"))
glmmod<-glm(formula=as.numeric(TURNINTENT)-1 ~ GAPPANTT+PRINACT2+DEGEARN2+TIMEEMPLOYED+I(TIMEEMPLOYED^2)+INSTCONT+OBEREG+NATENGSP+AGE+I(AGE^2)+NCHILD3+RACE, data=df_train, family = binomial) #937 observations lost to missingness (or 17 percent of the data)
RobustMod<-coeftest(glmmod, vcov = sandwich) # To get Robust SEs.
print(RobustMod)
#100*exp(RobustMod[,1]-1)
```

The backward selection process suggests the following important individual and work characteristics (alpha<0.05).  It also suggests that second order terms are appropriate for the effect of time employed and age. 

```{r Important_variables}
Impvars<-c("GAPPANTT","PRINACT2","DEGEARN2","TIMEEMPLOYED","INSTCONT","OBEREG","NATENGSP","AGE","NCHILD3","RACE")
print(Impvars)
```

# Model Evaluation with Training Data

Now we want to include the intermediary satisfaction variables.  Because satisfaction is a multi-dimensional construct, we need to model that in an SEM.  But first, we need to data wrangle.  Mplus has variable names constraints and binary requirements.

```{r Variable_Prep}
semdf_test<-df_test[names(df_test) %in% c(Impvars,names(dfS),"TURNINTENT","ACE")] # probably need to include for Mplus hierarchical analysis
options(na.action='na.pass') # required to keep na's in the model.matrix function
semdf_test<-data.frame(model.matrix(~ . -1, data=semdf_test))
options(na.action='na.omit')
semdf_test$TIMEEMPLOYED<-semdf_test$TIMEEMPLOYED-mean(semdf_test$TIMEEMPLOYED,na.rm=T)
semdf_test$TIMEEMPLOYED_SQ<-semdf_test$TIMEEMPLOYED^2 # Allow for non-linearity in time employed
semdf_test$AGE<-semdf_test$AGE-mean(semdf_test$AGE,na.rm=T)
semdf_test$AGE_SQ<-semdf_test$AGE^2 # Allow for non-linearity in time employed
#paste("TURNINTENTYes ~", paste(names(semdf_train)[-c(1:2)], collapse= "+"))

mdata<-semdf_test
col_idx <- grep("TURNINTENT", names(mdata))
mdata<- mdata[, c(col_idx, (1:ncol(mdata))[-col_idx])]
mdata[is.na(mdata)] <- "*"
mdata= mdata %>% select(-NATENGSPNo)
names(mdata)<-c('TURNINTE','ACE','SATIS01','SATIS02','SATIS03','SATIS04','SATIS05','SATIS06','SATIS07','SATIS08','SATIS09','SATIS10','SATIS11','SATIS12','SATIS13','SATIS14','SATIS15','SATIS16','SATIS17','SATIS18','SATIS20','English','Age','Public','WestOth','Midwest','South','GAPAA','GAPCE','GAPEx','GAPFree','Asian','Black','Hisp','RACEOth','DEGProf','DEGMast','DEGBAL','TIMEEMP','PRIRe','PRIAdOth','nChild','TIMEEMP2','Age2')
write.table(mdata, file.path(Private_Cache,"mp_test.txt"), sep="\t", col.names = F, row.names = F)
```

First, let's look at a simple model of adjunct class predicting attrition intentions.  Because of the computational demands of this series of analyses, I will use the bayesian estimator and the probit link (both of which improve computational efficiency).  Using probit is necessary at the moment in both Mplus and R.  I use Mplus and not R because Mplus integrates these requirements nicely along with FIML for the missing data.  This first analysis is a single level analysis because there are no level-two (institutional) characteristics in the model.  Models 2 and after all contain institutional level characteristics, so they were implemented as a Multi-level Bayesian SEM with probit link function.  Multi-level model was important to handle the dependency associated with level-two characteristics.

### Mplus Output
```{r, eval=FALSE}
HLM_Mod1<-"/Users/chadgevans/Research/Projects/Faculty_Satisfaction_Attrition/src/HLM_Mod1.out")
HLM_Mod2<-"/Users/chadgevans/Research/Projects/Faculty_Satisfaction_Attrition/src/HLM_Mod2.out")
HLM_Mod3<-"/Users/chadgevans/Research/Projects/Faculty_Satisfaction_Attrition/src/HLM_Mod3.out"
HLM_SEM<-"/Users/chadgevans/Research/Projects/Faculty_Satisfaction_Attrition/src/HLM_SEM.out"
```

## Bayesian Multi-level Models

```{r}
BayesianTables<-read.xls("/Users/chadgevans/Research/Projects/Faculty_Satisfaction_Attrition/doc/Bayesian_Tables.xlsx")
Btable<-BayesianTables[,c(1,2,3,7,8,9,13,14,15,19,20,21,25)]
kable(Btable)
```

```{r eval=FALSE}
write.csv(Btable, "/Users/chadgevans/Research/Projects/Faculty_Satisfaction_Attrition/doc/Final_Bayesian_Tables.csv")
```

```{r}
sessionInfo()
```


